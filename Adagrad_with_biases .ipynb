{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adagrad with biases.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiAQnoMsQhIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrmw7BIgQtoi",
        "colab_type": "code",
        "outputId": "e486a1ed-9e38-4c2c-a184-615c8a136f8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NimH1DadRirX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Add9M_vM4aAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-u4L_8pLo3n",
        "colab_type": "code",
        "outputId": "e9e93cb6-734b-4c2f-870a-b45ef2fa14fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-5-3033b8b99067>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAXrPd0qq9na",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_train = mnist.train.num_examples \n",
        "n_validation = mnist.validation.num_examples  \n",
        "n_test = mnist.test.num_examples  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQwQ03iirk-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_input = 784 \n",
        "#according to problem statement\n",
        "n_hidden1 = 1000  \n",
        "n_hidden2 = 1000\n",
        "n_hidden3 = 500\n",
        "n_hidden4 = 200\n",
        "n_output = 10  # 0-9 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmfqJjlPDuNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k =np.arange(0,100,2)\n",
        "#k=[0,5,10,20,25,30,35,40,45,50,55,60,65,70,75,80,90,92,95,97,99]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piw09YiZsCOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#parameters\n",
        "learning_rate = 0.00001\n",
        "n_iterations = 5000\n",
        "batch_size = 128\n",
        "dropout = 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHUCy_vdSBCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#place holder variables\n",
        "X = tf.placeholder(\"float\", [None, n_input])\n",
        "Y = tf.placeholder(\"float\", [None, n_output])\n",
        "keep_prob = tf.placeholder(tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoIXz38ZSG3n",
        "colab_type": "code",
        "outputId": "3ba34861-486b-4a96-8c69-30cf8e8fa40d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "a = tf.Variable(tf.truncated_normal([n_input, n_hidden1]))\n",
        "b = tf.Variable(tf.truncated_normal([n_hidden1, n_hidden2]))\n",
        "c = tf.Variable(tf.truncated_normal([n_hidden2, n_hidden3]))\n",
        "d = tf.Variable(tf.truncated_normal([n_hidden3, n_hidden4]))\n",
        "e = tf.Variable(tf.truncated_normal([n_hidden4, n_output]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OvNlNEMkXhK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = {\n",
        "    'w1': a,\n",
        "    'w2': b,\n",
        "    'w3': c,\n",
        "    'w4': d,\n",
        "    'out': e\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22EXGytZsWNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "biases = {\n",
        "    'b1': tf.Variable(tf.constant(0.1, shape=[n_hidden1])),\n",
        "    'b2': tf.Variable(tf.constant(0.1, shape=[n_hidden2])),\n",
        "    'b3': tf.Variable(tf.constant(0.1, shape=[n_hidden3])),\n",
        "    'b4': tf.Variable(tf.constant(0.1, shape=[n_hidden4])),\n",
        "    'out': tf.Variable(tf.constant(0.1, shape=[n_output]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LTYNSIDsukK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po6-5JfTsZAj",
        "colab_type": "code",
        "outputId": "eb788045-2dba-4023-8627-cb176a10546a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "layer_1 = tf.add(tf.matmul(X, weights['w1']), biases['b1'])\n",
        "layer_1 = tf.nn.relu(layer_1)\n",
        "layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
        "layer_2 = tf.nn.relu(layer_2)\n",
        "layer_3 = tf.add(tf.matmul(layer_2, weights['w3']), biases['b3'])\n",
        "layer_3 = tf.nn.relu(layer_3)\n",
        "layer_4 = tf.add(tf.matmul(layer_3,weights['w4']),biases['b4'])\n",
        "layer_4 = tf.nn.relu(layer_4)\n",
        "layer_drop = tf.nn.dropout(layer_4, keep_prob)\n",
        "output_layer = tf.matmul(layer_4, weights['out']) + biases['out']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-14-0dd4a2dac366>:9: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "190TUYWMsvqZ",
        "colab_type": "code",
        "outputId": "9244be14-6272-4320-b4dc-0be3c10b15a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=output_layer))\n",
        "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-15-812430f7e244>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fahov9ms9JR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_pred = tf.equal(tf.argmax(output_layer, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb9vET-7SlP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P548QtgTtC5J",
        "colab_type": "code",
        "outputId": "58d733a6-ffb6-443c-f1af-ebf3b47da964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "for i in range(n_iterations):\n",
        "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "    sess.run(train_step, feed_dict={\n",
        "        X: batch_x, Y: batch_y, keep_prob: dropout\n",
        "        })\n",
        "\n",
        "    # print loss and accuracy (per minibatch)\n",
        "    if i % 100 == 0:\n",
        "        minibatch_loss, minibatch_accuracy = sess.run([cross_entropy, accuracy],feed_dict={X: batch_x, Y: batch_y, keep_prob: 1.0})\n",
        "        print(\"Iteration\",str(i),\"\\t| Loss =\",str(minibatch_loss),\"\\t| Accuracy =\",str(minibatch_accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 0 \t| Loss = 808477.4 \t| Accuracy = 0.1171875\n",
            "Iteration 100 \t| Loss = 102465.81 \t| Accuracy = 0.375\n",
            "Iteration 200 \t| Loss = 90641.57 \t| Accuracy = 0.53125\n",
            "Iteration 300 \t| Loss = 47027.867 \t| Accuracy = 0.609375\n",
            "Iteration 400 \t| Loss = 21275.262 \t| Accuracy = 0.7890625\n",
            "Iteration 500 \t| Loss = 21385.146 \t| Accuracy = 0.7890625\n",
            "Iteration 600 \t| Loss = 29992.836 \t| Accuracy = 0.7734375\n",
            "Iteration 700 \t| Loss = 29733.611 \t| Accuracy = 0.78125\n",
            "Iteration 800 \t| Loss = 16531.465 \t| Accuracy = 0.859375\n",
            "Iteration 900 \t| Loss = 16161.283 \t| Accuracy = 0.8359375\n",
            "Iteration 1000 \t| Loss = 17706.85 \t| Accuracy = 0.8203125\n",
            "Iteration 1100 \t| Loss = 15889.618 \t| Accuracy = 0.7890625\n",
            "Iteration 1200 \t| Loss = 12616.734 \t| Accuracy = 0.84375\n",
            "Iteration 1300 \t| Loss = 11027.944 \t| Accuracy = 0.8828125\n",
            "Iteration 1400 \t| Loss = 10744.167 \t| Accuracy = 0.8671875\n",
            "Iteration 1500 \t| Loss = 16389.664 \t| Accuracy = 0.828125\n",
            "Iteration 1600 \t| Loss = 10838.636 \t| Accuracy = 0.8515625\n",
            "Iteration 1700 \t| Loss = 15600.453 \t| Accuracy = 0.8828125\n",
            "Iteration 1800 \t| Loss = 13497.562 \t| Accuracy = 0.9140625\n",
            "Iteration 1900 \t| Loss = 5438.331 \t| Accuracy = 0.9375\n",
            "Iteration 2000 \t| Loss = 4009.6926 \t| Accuracy = 0.8984375\n",
            "Iteration 2100 \t| Loss = 13670.963 \t| Accuracy = 0.8515625\n",
            "Iteration 2200 \t| Loss = 6237.675 \t| Accuracy = 0.953125\n",
            "Iteration 2300 \t| Loss = 7292.0645 \t| Accuracy = 0.8984375\n",
            "Iteration 2400 \t| Loss = 7805.3877 \t| Accuracy = 0.8828125\n",
            "Iteration 2500 \t| Loss = 7570.498 \t| Accuracy = 0.8984375\n",
            "Iteration 2600 \t| Loss = 1710.9087 \t| Accuracy = 0.953125\n",
            "Iteration 2700 \t| Loss = 5972.394 \t| Accuracy = 0.9375\n",
            "Iteration 2800 \t| Loss = 5021.33 \t| Accuracy = 0.9296875\n",
            "Iteration 2900 \t| Loss = 5554.984 \t| Accuracy = 0.8984375\n",
            "Iteration 3000 \t| Loss = 7815.193 \t| Accuracy = 0.9375\n",
            "Iteration 3100 \t| Loss = 3895.8464 \t| Accuracy = 0.9296875\n",
            "Iteration 3200 \t| Loss = 8287.993 \t| Accuracy = 0.890625\n",
            "Iteration 3300 \t| Loss = 3520.288 \t| Accuracy = 0.9375\n",
            "Iteration 3400 \t| Loss = 4651.6123 \t| Accuracy = 0.9375\n",
            "Iteration 3500 \t| Loss = 7782.066 \t| Accuracy = 0.9453125\n",
            "Iteration 3600 \t| Loss = 3765.6804 \t| Accuracy = 0.9609375\n",
            "Iteration 3700 \t| Loss = 2982.0852 \t| Accuracy = 0.953125\n",
            "Iteration 3800 \t| Loss = 4715.68 \t| Accuracy = 0.9453125\n",
            "Iteration 3900 \t| Loss = 2271.5288 \t| Accuracy = 0.953125\n",
            "Iteration 4000 \t| Loss = 96.96411 \t| Accuracy = 0.9921875\n",
            "Iteration 4100 \t| Loss = 5845.201 \t| Accuracy = 0.9140625\n",
            "Iteration 4200 \t| Loss = 2682.9497 \t| Accuracy = 0.953125\n",
            "Iteration 4300 \t| Loss = 4874.299 \t| Accuracy = 0.9453125\n",
            "Iteration 4400 \t| Loss = 3033.3198 \t| Accuracy = 0.953125\n",
            "Iteration 4500 \t| Loss = 5830.463 \t| Accuracy = 0.9140625\n",
            "Iteration 4600 \t| Loss = 2642.4956 \t| Accuracy = 0.9296875\n",
            "Iteration 4700 \t| Loss = 2901.6697 \t| Accuracy = 0.9609375\n",
            "Iteration 4800 \t| Loss = 263.1751 \t| Accuracy = 0.984375\n",
            "Iteration 4900 \t| Loss = 506.42078 \t| Accuracy = 0.9765625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly0b_7ca0c8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save the model\n",
        "saver = tf.train.Saver()\n",
        "save_path = saver.save(sess, \"/tmp/model.ckpt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOUiwmULMeTL",
        "colab_type": "code",
        "outputId": "49a0aff7-c452-45d7-893a-3d3314f1a21e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "  saver.restore(sess, \"/tmp/model.ckpt\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9Ag6tDKtFyh",
        "colab_type": "code",
        "outputId": "6d06fd16-5937-460d-cf73-1b2196f4c1a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_accuracy = sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1.0})\n",
        "print(\"\\nAccuracy on test set:\", test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy on test set: 0.9127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsVvrsI9uf1X",
        "colab_type": "code",
        "outputId": "48b30e8e-ccb2-40c5-faff-183775dfa326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'Variable:0' shape=(784, 1000) dtype=float32_ref>,\n",
              " <tf.Variable 'Variable_1:0' shape=(1000, 1000) dtype=float32_ref>,\n",
              " <tf.Variable 'Variable_2:0' shape=(1000, 500) dtype=float32_ref>,\n",
              " <tf.Variable 'Variable_3:0' shape=(500, 200) dtype=float32_ref>,\n",
              " <tf.Variable 'Variable_4:0' shape=(200, 10) dtype=float32_ref>,\n",
              " <tf.Variable 'Variable_5:0' shape=(1000,) dtype=float32_ref>,\n",
              " <tf.Variable 'Variable_6:0' shape=(1000,) dtype=float32_ref>,\n",
              " <tf.Variable 'Variable_7:0' shape=(500,) dtype=float32_ref>,\n",
              " <tf.Variable 'Variable_8:0' shape=(200,) dtype=float32_ref>,\n",
              " <tf.Variable 'Variable_9:0' shape=(10,) dtype=float32_ref>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrd7TRK3kHS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_indices_of_k_smallest(arr, k):\n",
        "    idx = np.argpartition(arr.ravel(), k)\n",
        "    return np.array(np.unravel_index(idx, arr.shape))[:, range(k)].transpose().tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2C4co7CsgIP",
        "colab_type": "text"
      },
      "source": [
        "## Weight pruning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3izMVVif-Zu",
        "colab_type": "text"
      },
      "source": [
        "Loop from here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdedOPXxgMcp",
        "colab_type": "code",
        "outputId": "d82e4ca4-892d-41b8-e3db-921109f9d202",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2567
        }
      },
      "source": [
        "plt_var = np.zeros(len(k))\n",
        "for p in range(len(k)):\n",
        "  saver.restore(sess, \"/tmp/model.ckpt\")\n",
        "  var1 = [v for v in tf.trainable_variables() if v.name == \"Variable:0\"]\n",
        "  var2 = [v for v in tf.trainable_variables() if v.name == \"Variable_1:0\"]\n",
        "  var3 = [v for v in tf.trainable_variables() if v.name == \"Variable_2:0\"]\n",
        "  var4 = [v for v in tf.trainable_variables() if v.name == \"Variable_3:0\"]\n",
        "  l=sess.run(var1)\n",
        "  l = np.array(l)\n",
        "  l =l.reshape(784,1000)\n",
        "  m=sess.run(var2)\n",
        "  m = np.array(m)\n",
        "  m =m.reshape(1000,1000)\n",
        "  n=sess.run(var3)\n",
        "  n = np.array(n)\n",
        "  n =n.reshape(1000,500)\n",
        "  o=sess.run(var4)\n",
        "  o = np.array(o)\n",
        "  o =o.reshape(500,200)\n",
        "  w = get_indices_of_k_smallest(l,int(1000*k[p]/100))\n",
        "  x = get_indices_of_k_smallest(m,int(1000*k[p]/100))\n",
        "  y = get_indices_of_k_smallest(n,int(500*k[p]/100))\n",
        "  z = get_indices_of_k_smallest(o,int(200*k[p]/100))\n",
        "  for _ in w:\n",
        "    l[_[0]][_[1]]=0\n",
        "  for _ in x:\n",
        "    m[_[0]][_[1]]=0\n",
        "  for _ in y:\n",
        "    n[_[0]][_[1]]=0\n",
        "  for _ in z:\n",
        "    o[_[0]][_[1]]=0\n",
        "  sess.run(a.assign(l))\n",
        "  sess.run(b.assign(m))\n",
        "  sess.run(c.assign(n))\n",
        "  sess.run(d.assign(o))\n",
        "\n",
        "  test_accuracy = sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1.0})\n",
        "  print(\"\\nAccuracy on test set:\", test_accuracy)  \n",
        "  plt_var[p] = test_accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.9127\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.9115\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.9104\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.9087\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.9082\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.9076\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.9067\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.9057\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.9054\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.9046\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.9028\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.9024\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.9011\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8984\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8983\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8977\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.896\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8977\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8976\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8957\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8932\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8921\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8922\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8912\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8884\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8863\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.883\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8807\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8813\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8802\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8794\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8797\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8804\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8808\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8777\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8769\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8782\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8786\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8789\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8785\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8771\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8771\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8738\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8718\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8709\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8703\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8676\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8667\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8681\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "845BLiIugXPW",
        "colab_type": "text"
      },
      "source": [
        "END LOOP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5wpXcRmur_X",
        "colab_type": "text"
      },
      "source": [
        "## unit pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9cP_uq2kq8O",
        "colab_type": "code",
        "outputId": "342b1353-88c7-474c-b843-7449fe402ae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2567
        }
      },
      "source": [
        "unit_prune_plot_var = np.zeros(len(k))\n",
        "for p in range(len(k)):\n",
        "  saver.restore(sess, \"/tmp/model.ckpt\")\n",
        "\n",
        "  var1 = [v for v in tf.trainable_variables() if v.name == \"Variable_1:0\"]\n",
        "  var2 = [v for v in tf.trainable_variables() if v.name == \"Variable_2:0\"]\n",
        "  var3 = [v for v in tf.trainable_variables() if v.name == \"Variable_3:0\"]\n",
        "  var4 = [v for v in tf.trainable_variables() if v.name == \"Variable_4:0\"]\n",
        "  l=sess.run(var1)\n",
        "  l = np.array(l)\n",
        "  l =l.reshape(1000,1000)\n",
        "  m=sess.run(var2)\n",
        "  m = np.array(m)\n",
        "  m =m.reshape(1000,500)\n",
        "  n=sess.run(var3)\n",
        "  n = np.array(n)\n",
        "  n =n.reshape(500,200)\n",
        "  o=sess.run(var4)\n",
        "  o = np.array(o)\n",
        "  o =o.reshape(200,10)\n",
        "\n",
        "  ff = sess.run(tf.norm(b,ord=2,axis=1))\n",
        "  gg = sess.run(tf.norm(c,ord=2,axis=1))\n",
        "  hh = sess.run(tf.norm(d,ord=2,axis=1))\n",
        "  ii = sess.run(tf.norm(e,ord=2,axis=1))\n",
        "\n",
        "  w = get_indices_of_k_smallest(ff,int(1000*k[p]/100))\n",
        "  x = get_indices_of_k_smallest(gg,int(1000*k[p]/100))\n",
        "  y = get_indices_of_k_smallest(hh,int(500*k[p]/100))\n",
        "  z = get_indices_of_k_smallest(ii,int(200*k[p]/100))\n",
        "  for _ in w:\n",
        "    l[_[0]]=0\n",
        "  for _ in x:\n",
        "    m[_[0]]=0\n",
        "  for _ in y:\n",
        "    n[_[0]]=0\n",
        "  for _ in z:\n",
        "    o[_[0]]=0\n",
        "\n",
        "  sess.run(b.assign(l))\n",
        "  sess.run(c.assign(m))\n",
        "  sess.run(d.assign(n))\n",
        "  sess.run(e.assign(o))\n",
        "\n",
        "  test_accuracy = sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1.0})\n",
        "  print(\"\\nAccuracy on test set:\", test_accuracy)  \n",
        "    \n",
        "  unit_prune_plot_var[p]=test_accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.9127\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8811\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.8609\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.7838\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.7109\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.6932\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.6984\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.5912\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.5055\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.4462\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.3931\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.4001\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.3778\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.3705\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.3309\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.2875\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.2662\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.2462\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.2288\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.2223\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.1908\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.1703\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.1653\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.1873\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.1666\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.1855\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.1516\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.1572\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.1861\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.1675\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.1622\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.1855\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.1342\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.1521\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.131\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.1188\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.0906\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.1036\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.0817\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.0951\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.0743\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.0796\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.0917\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.0536\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.0889\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.0731\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.1113\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.0933\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.0909\n",
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "\n",
            "Accuracy on test set: 0.0695\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utOTJbudkD9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4HWc4BqkK_h",
        "colab_type": "code",
        "outputId": "3ee013a3-f6e1-43af-eb30-52692b2a2d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.plot(k,plt_var,'b+',label=\"weight pruning\")\n",
        "plt.plot(k, unit_prune_plot_var,'ro',label=\"unit pruning\")\n",
        "plt.xlabel(\"% sparsity\")\n",
        "plt.ylabel(\"% accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrUQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvRWz-aDHR4Q",
        "colab_type": "code",
        "outputId": "8c8e6c2d-0c8c-462a-c537-78861ec43a63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        }
      },
      "source": [
        "plt.plot(k,plt_var,'b')\n",
        "plt.xlabel(\"% sparsity\")\n",
        "plt.ylabel(\"% accuracy\")\n",
        "plt.show()\n",
        "plt.plot(k,unit_prune_plot_var,'r')\n",
        "plt.xlabel(\"% sparsity\")\n",
        "plt.ylabel(\"% accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ5p0zbX8Z9W",
        "colab_type": "code",
        "outputId": "3bb394c2-5b5f-4e4d-c3da-0a186d6cb3c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1599
        }
      },
      "source": [
        "#dic1 = {k:unit_prune_plot_var}\n",
        "#dic2 = {k:plt_var}\n",
        "\n",
        "\n",
        "pd.DataFrame({'K% Sparsity':k,'WP acc.':plt_var,'UP acc.':unit_prune_plot_var})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>K% Sparsity</th>\n",
              "      <th>WP acc.</th>\n",
              "      <th>UP acc.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.9127</td>\n",
              "      <td>0.9127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.9115</td>\n",
              "      <td>0.8811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>0.9104</td>\n",
              "      <td>0.8609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>0.9087</td>\n",
              "      <td>0.7838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>0.9082</td>\n",
              "      <td>0.7109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10</td>\n",
              "      <td>0.9076</td>\n",
              "      <td>0.6932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>12</td>\n",
              "      <td>0.9067</td>\n",
              "      <td>0.6984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>14</td>\n",
              "      <td>0.9057</td>\n",
              "      <td>0.5912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>16</td>\n",
              "      <td>0.9054</td>\n",
              "      <td>0.5055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>18</td>\n",
              "      <td>0.9046</td>\n",
              "      <td>0.4462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>20</td>\n",
              "      <td>0.9028</td>\n",
              "      <td>0.3931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>22</td>\n",
              "      <td>0.9024</td>\n",
              "      <td>0.4001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>24</td>\n",
              "      <td>0.9011</td>\n",
              "      <td>0.3778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>26</td>\n",
              "      <td>0.8984</td>\n",
              "      <td>0.3705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>28</td>\n",
              "      <td>0.8983</td>\n",
              "      <td>0.3309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>30</td>\n",
              "      <td>0.8977</td>\n",
              "      <td>0.2875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>32</td>\n",
              "      <td>0.8960</td>\n",
              "      <td>0.2662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>34</td>\n",
              "      <td>0.8977</td>\n",
              "      <td>0.2462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>36</td>\n",
              "      <td>0.8976</td>\n",
              "      <td>0.2288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>38</td>\n",
              "      <td>0.8957</td>\n",
              "      <td>0.2223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>40</td>\n",
              "      <td>0.8932</td>\n",
              "      <td>0.1908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>42</td>\n",
              "      <td>0.8921</td>\n",
              "      <td>0.1703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>44</td>\n",
              "      <td>0.8922</td>\n",
              "      <td>0.1653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>46</td>\n",
              "      <td>0.8912</td>\n",
              "      <td>0.1873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>48</td>\n",
              "      <td>0.8884</td>\n",
              "      <td>0.1666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>50</td>\n",
              "      <td>0.8863</td>\n",
              "      <td>0.1855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>52</td>\n",
              "      <td>0.8830</td>\n",
              "      <td>0.1516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>54</td>\n",
              "      <td>0.8807</td>\n",
              "      <td>0.1572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>56</td>\n",
              "      <td>0.8813</td>\n",
              "      <td>0.1861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>58</td>\n",
              "      <td>0.8802</td>\n",
              "      <td>0.1675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>60</td>\n",
              "      <td>0.8794</td>\n",
              "      <td>0.1622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>62</td>\n",
              "      <td>0.8797</td>\n",
              "      <td>0.1855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>64</td>\n",
              "      <td>0.8804</td>\n",
              "      <td>0.1342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>66</td>\n",
              "      <td>0.8808</td>\n",
              "      <td>0.1521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>68</td>\n",
              "      <td>0.8777</td>\n",
              "      <td>0.1310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>70</td>\n",
              "      <td>0.8769</td>\n",
              "      <td>0.1188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>72</td>\n",
              "      <td>0.8782</td>\n",
              "      <td>0.0906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>74</td>\n",
              "      <td>0.8786</td>\n",
              "      <td>0.1036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>76</td>\n",
              "      <td>0.8789</td>\n",
              "      <td>0.0817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>78</td>\n",
              "      <td>0.8785</td>\n",
              "      <td>0.0951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>80</td>\n",
              "      <td>0.8771</td>\n",
              "      <td>0.0743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>82</td>\n",
              "      <td>0.8771</td>\n",
              "      <td>0.0796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>84</td>\n",
              "      <td>0.8738</td>\n",
              "      <td>0.0917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>86</td>\n",
              "      <td>0.8718</td>\n",
              "      <td>0.0536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>88</td>\n",
              "      <td>0.8709</td>\n",
              "      <td>0.0889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>90</td>\n",
              "      <td>0.8703</td>\n",
              "      <td>0.0731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>92</td>\n",
              "      <td>0.8676</td>\n",
              "      <td>0.1113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>94</td>\n",
              "      <td>0.8667</td>\n",
              "      <td>0.0933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>96</td>\n",
              "      <td>0.8681</td>\n",
              "      <td>0.0909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>98</td>\n",
              "      <td>0.8677</td>\n",
              "      <td>0.0695</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    K% Sparsity  WP acc.  UP acc.\n",
              "0             0   0.9127   0.9127\n",
              "1             2   0.9115   0.8811\n",
              "2             4   0.9104   0.8609\n",
              "3             6   0.9087   0.7838\n",
              "4             8   0.9082   0.7109\n",
              "5            10   0.9076   0.6932\n",
              "6            12   0.9067   0.6984\n",
              "7            14   0.9057   0.5912\n",
              "8            16   0.9054   0.5055\n",
              "9            18   0.9046   0.4462\n",
              "10           20   0.9028   0.3931\n",
              "11           22   0.9024   0.4001\n",
              "12           24   0.9011   0.3778\n",
              "13           26   0.8984   0.3705\n",
              "14           28   0.8983   0.3309\n",
              "15           30   0.8977   0.2875\n",
              "16           32   0.8960   0.2662\n",
              "17           34   0.8977   0.2462\n",
              "18           36   0.8976   0.2288\n",
              "19           38   0.8957   0.2223\n",
              "20           40   0.8932   0.1908\n",
              "21           42   0.8921   0.1703\n",
              "22           44   0.8922   0.1653\n",
              "23           46   0.8912   0.1873\n",
              "24           48   0.8884   0.1666\n",
              "25           50   0.8863   0.1855\n",
              "26           52   0.8830   0.1516\n",
              "27           54   0.8807   0.1572\n",
              "28           56   0.8813   0.1861\n",
              "29           58   0.8802   0.1675\n",
              "30           60   0.8794   0.1622\n",
              "31           62   0.8797   0.1855\n",
              "32           64   0.8804   0.1342\n",
              "33           66   0.8808   0.1521\n",
              "34           68   0.8777   0.1310\n",
              "35           70   0.8769   0.1188\n",
              "36           72   0.8782   0.0906\n",
              "37           74   0.8786   0.1036\n",
              "38           76   0.8789   0.0817\n",
              "39           78   0.8785   0.0951\n",
              "40           80   0.8771   0.0743\n",
              "41           82   0.8771   0.0796\n",
              "42           84   0.8738   0.0917\n",
              "43           86   0.8718   0.0536\n",
              "44           88   0.8709   0.0889\n",
              "45           90   0.8703   0.0731\n",
              "46           92   0.8676   0.1113\n",
              "47           94   0.8667   0.0933\n",
              "48           96   0.8681   0.0909\n",
              "49           98   0.8677   0.0695"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO2MoBiodG6b",
        "colab_type": "code",
        "outputId": "67a23e87-66dd-4323-d694-586c2e4ed857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"def NN_model(data):\n",
        "  hidden1 = {'weights':tf.Variable(tf.random_normal([784,nodes_h1])),'biases':tf.Variable(tf.random_normal([nodes_h1]))}\n",
        "  hidden2 = {'weights':tf.Variable(tf.random_normal([nodes_h1,nodes_h2])),'biases':tf.Variable(tf.random_normal([nodes_h2]))}\n",
        "  hidden3 = {'weights':tf.Variable(tf.random_normal([nodes_h2,nodes_h3])),'biases':tf.Variable(tf.random_normal([nodes_h3]))}\n",
        "  hidden4 = {'weights':tf.Variable(tf.random_normal([nodes_h3,nodes_h4])),'biases':tf.Variable(tf.random_normal([nodes_h4]))}\n",
        "  output = {'weights':tf.Variable(tf.random_normal([nodes_h4,num_classes])),'biases':tf.Variable(tf.random_normal([num_classes]))}\n",
        "   \n",
        "  layer1 = tf.add(tf.matmul(data,hidden1['weights']),hidden1['biases'])\n",
        "  layer1 = tf.nn.relu(layer1)\n",
        "  \n",
        "  layer2 = tf.add(tf.matmul(layer1,hidden2['weights']),hidden2['biases'])\n",
        "  layer2 = tf.nn.relu(layer2)\n",
        "  \n",
        "  layer3 = tf.add(tf.matmul(layer2,hidden3['weights']),hidden3['biases'])\n",
        "  layer3 = tf.nn.relu(layer3)\n",
        " \n",
        "  layer4 = tf.add(tf.matmul(layer3,hidden4['weights']),hidden4['biases'])\n",
        "  layer4 = tf.nn.relu(layer4)\n",
        "   \n",
        "  \n",
        "  output_layer = tf.matmul(layer4,output['weights']),output['biases']\n",
        "\n",
        "  return output_layer\n",
        "\"\"\"  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"def NN_model(data):\\n  hidden1 = {'weights':tf.Variable(tf.random_normal([784,nodes_h1])),'biases':tf.Variable(tf.random_normal([nodes_h1]))}\\n  hidden2 = {'weights':tf.Variable(tf.random_normal([nodes_h1,nodes_h2])),'biases':tf.Variable(tf.random_normal([nodes_h2]))}\\n  hidden3 = {'weights':tf.Variable(tf.random_normal([nodes_h2,nodes_h3])),'biases':tf.Variable(tf.random_normal([nodes_h3]))}\\n  hidden4 = {'weights':tf.Variable(tf.random_normal([nodes_h3,nodes_h4])),'biases':tf.Variable(tf.random_normal([nodes_h4]))}\\n  output = {'weights':tf.Variable(tf.random_normal([nodes_h4,num_classes])),'biases':tf.Variable(tf.random_normal([num_classes]))}\\n   \\n  layer1 = tf.add(tf.matmul(data,hidden1['weights']),hidden1['biases'])\\n  layer1 = tf.nn.relu(layer1)\\n  \\n  layer2 = tf.add(tf.matmul(layer1,hidden2['weights']),hidden2['biases'])\\n  layer2 = tf.nn.relu(layer2)\\n  \\n  layer3 = tf.add(tf.matmul(layer2,hidden3['weights']),hidden3['biases'])\\n  layer3 = tf.nn.relu(layer3)\\n \\n  layer4 = tf.add(tf.matmul(layer3,hidden4['weights']),hidden4['biases'])\\n  layer4 = tf.nn.relu(layer4)\\n   \\n  \\n  output_layer = tf.matmul(layer4,output['weights']),output['biases']\\n\\n  return output_layer\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT0P_8UsmlWz",
        "colab_type": "code",
        "outputId": "03ff5b1e-5355-4b3e-fa09-c7f8d855667c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"def train(x):\n",
        "  predict = NN_model(x)\n",
        "  cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predict,labels=y))\n",
        "  \n",
        "  optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
        "  \n",
        "  with tf.Session as sess:\n",
        "      sess.run(tf.initialize_all_variables())\n",
        "      \n",
        "      for i in epoch:\n",
        "        loss =0\n",
        "        for _ in range(int(mnist.train.num_examples/batch_size)):\n",
        "          a,b= mnist.train.next_batch(batch_size)\n",
        "          _,c = sess.run([optimizer,cost],feed_dict={x:a, y:b})\n",
        "          loss += c\n",
        "        print('Epoch',i,'completed out of',epoch,'loss:',loss)\n",
        "        \n",
        "        correct = tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n",
        "        \n",
        "        accuracy = tf.reduce_mean(tf.cast(correct,'float'))\n",
        "        print('Accuracy:',accuracy.eval({x:mnist.test.images, y:mnist.test.labels}))\n",
        "        \n",
        "\"\"\"       "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"def train(x):\\n  predict = NN_model(x)\\n  cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predict,labels=y))\\n  \\n  optimizer = tf.train.AdamOptimizer().minimize(cost)\\n  \\n  with tf.Session as sess:\\n      sess.run(tf.initialize_all_variables())\\n      \\n      for i in epoch:\\n        loss =0\\n        for _ in range(int(mnist.train.num_examples/batch_size)):\\n          a,b= mnist.train.next_batch(batch_size)\\n          _,c = sess.run([optimizer,cost],feed_dict={x:a, y:b})\\n          loss += c\\n        print('Epoch',i,'completed out of',epoch,'loss:',loss)\\n        \\n        correct = tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\\n        \\n        accuracy = tf.reduce_mean(tf.cast(correct,'float'))\\n        print('Accuracy:',accuracy.eval({x:mnist.test.images, y:mnist.test.labels}))\\n        \\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et1ZqukUTHY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}